{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "607a0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b620e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_test(data_path, label_to_predict, drop_col=[]):\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Imported dataframe shape: \", df.shape)\n",
    "\n",
    "    #Only use quant variables and drop any rows with missing values\n",
    "    num_vars = df.select_dtypes(include=['int', 'float'])\n",
    "    num_vars = num_vars.drop(drop_col, axis=1)\n",
    "    print(\"Dataframe shape with only numeric value columns: \", num_vars.shape)\n",
    "\n",
    "    num_vars = num_vars.dropna(subset=[label_to_predict], axis=0)\n",
    "    print(f\"Dataframe shape when nan value is dropped in label({label_to_predict}): \", num_vars.shape)\n",
    "\n",
    "    # Mean function\n",
    "    fill_mean = lambda col: col.fillna(col.mean())\n",
    "    # Fill the mean\n",
    "    num_vars = num_vars.apply(fill_mean, axis=0)\n",
    "\n",
    "    #Split into explanatory and response variables\n",
    "    X = num_vars.drop(label_to_predict, axis=1)\n",
    "    y = num_vars[label_to_predict]\n",
    "\n",
    "    #Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42) \n",
    "\n",
    "    lm_model = LinearRegression(normalize=True) # Instantiate\n",
    "    lm_model.fit(X_train, y_train) #Fit\n",
    "\n",
    "    #Predict and score the model\n",
    "    y_test_preds = lm_model.predict(X_test) \n",
    "    print(\"The r-squared score for the model using only quantitative variables was {} on {} values.\".format(r2_score(y_test, y_test_preds), len(y_test)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9cff83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_cols(df):\n",
    "    cat_df = df.select_dtypes(include=['object'])\n",
    "    cat_cols_lst = cat_df.columns\n",
    "    print(\"Object columns from this df: \", cat_df.shape[1])\n",
    "    return cat_cols_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ac21d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_value_cols(df):\n",
    "    contain_semicolons = df.apply(lambda col: \n",
    "                                  col.str.contains(';').any()\n",
    "                                  if col.dtypes==object\n",
    "                                  else False)\n",
    "    df_contain_semicolons = df.loc[:, contain_semicolons]\n",
    "    columns_with_multiple_values = df_contain_semicolons.columns\n",
    "    return columns_with_multiple_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_dict(columns_with_multiple_values):\n",
    "    categorized_df_dict = {}\n",
    "    categorized_df_names_list = []\n",
    "    for col in columns_with_multiple_values:\n",
    "        df_categorized = categorize_feature(df[col])\n",
    "        categorized_df_dict[col] = df_categorized\n",
    "        categorized_df_names_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "51354360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_lecture_method(df, cat_cols, dummy_na):\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            print(col, 'Exception occur!!')\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "def create_dummy_my_method(df, cat_cols, _):\n",
    "    for col in cat_cols:\n",
    "        try:\n",
    "            df1 = df[col]\n",
    "        except:\n",
    "            continue\n",
    "        df1 = categorize_feature(df1)\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        df = pd.concat([df, df1], axis=1)\n",
    "    return df\n",
    "\n",
    "def categorize_feature(single_column):\n",
    "    if single_column.name in columns_with_multiple_values:\n",
    "        single_column = single_column.apply(lambda value: list(value.split(';'))\n",
    "                           if type(value)!=float\n",
    "                           else float('nan'))\n",
    "        print(124124124)\n",
    "        return pd.get_dummies(single_column.apply(pd.Series).stack(dropna=False), prefix=single_column.name, prefix_sep='_').sum(level=0)\n",
    "    \n",
    "    else:\n",
    "        return pd.get_dummies(single_column, prefix=single_column.name, prefix_sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a3cb40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fit_linear_mod(df, response_col, func_dummy, dummy_na, test_size=.3, rand_state=42):\n",
    "    #Drop the rows with missing response values\n",
    "    df  = df.dropna(subset=response_col, axis=0)\n",
    "    print(\"Shape of df: \", df.shape)\n",
    "\n",
    "    #Drop columns with all NaN values\n",
    "    df = df.dropna(how='all', axis=1)\n",
    "    \n",
    "    # drop Respondent column\n",
    "    df = df.drop('Respondent', axis=1)\n",
    "    \n",
    "    for column in df.select_dtypes(include=['int', 'float']):\n",
    "        # Mean function\n",
    "#         fill_mean = lambda col: col.fillna(col.mean())\n",
    "        # Fill the mean\n",
    "        df[column] = df[column].fillna(df[column].mean(), axis=0)\n",
    "        \n",
    "    \n",
    "    cat_cols = get_object_cols(df)\n",
    "    \n",
    "    #Dummy categorical variables\n",
    "    df = func_dummy(df, cat_cols, dummy_na)\n",
    "    print(\"Shape of dummy df: \", df.shape)   \n",
    "    \n",
    "    \n",
    "    #Split into explanatory and response variables\n",
    "    X = df.drop(response_col, axis=1)\n",
    "    y = df[response_col]\n",
    "    \n",
    "    print(\"Shape of X: \", X.shape)\n",
    "    \n",
    "    #Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=rand_state)\n",
    "\n",
    "    lm_model = LinearRegression(normalize=True) # Instantiate\n",
    "    lm_model.fit(X_train, y_train) #Fit\n",
    "\n",
    "    #Predict using your model\n",
    "    y_test_preds = lm_model.predict(X_test)\n",
    "    y_train_preds = lm_model.predict(X_train)\n",
    "\n",
    "    #Score using your model\n",
    "    test_score = r2_score(y_test, y_test_preds)\n",
    "    train_score = r2_score(y_train, y_train_preds)\n",
    "    \n",
    "    print(\"The rsquared on the training data was {}.  The rsquared on the test data was {}.\".format(train_score, test_score))\n",
    "    \n",
    "    return test_score, train_score, lm_model, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183cd104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae331f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6bfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea4c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee50bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69585059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "039702fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported dataframe shape:  (51392, 154)\n",
      "Dataframe shape with only numeric value columns:  (51392, 6)\n",
      "Dataframe shape when nan value is dropped in label(Salary):  (12891, 6)\n",
      "The r-squared score for the model using only quantitative variables was 0.04113420903416998 on 3868 values.\n",
      "Shape of df:  (12891, 154)\n",
      "Object column size from this df:  141\n",
      "Shape of dummy df:  (12891, 21108)\n",
      "Shape of X:  (12891, 21107)\n"
     ]
    }
   ],
   "source": [
    "df_2017 = import_and_test('./survey_results_public_2017.csv', 'Salary', 'ExpectedSalary')\n",
    "print('Import complete', '-'*40)\n",
    "label_to_predict = 'Salary'\n",
    "X, y = clean_fit_linear_mod(df_2017, label_to_predict, create_dummy_lecture_method, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15afe968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ExCoderNotForMe' in X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1fae6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported dataframe shape:  (98855, 129)\n",
      "Dataframe shape with only numeric value columns:  (98855, 42)\n",
      "Dataframe shape when nan value is dropped in label(ConvertedSalary):  (47702, 42)\n",
      "The r-squared score for the model using only quantitative variables was 0.019991430883123606 on 14311 values.\n",
      "Shape of df:  (47702, 129)\n",
      "Object column size from this df:  87\n",
      "Shape of dummy df:  (47702, 86960)\n",
      "Shape of X:  (47702, 86959)\n"
     ]
    }
   ],
   "source": [
    "# import 2018 dataset\n",
    "df_2018 = import_and_test('./survey_results_public_2018.csv', 'ConvertedSalary')\n",
    "print('Import complete', '-'*40)\n",
    "label_to_predict = 'ConvertedSalary'\n",
    "X, y = clean_fit_linear_mod(df_2018, label_to_predict, create_dummy_lecture_method, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dfbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbfd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a2e17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15a085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711aa92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "999d0429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported dataframe shape:  (51392, 154)\n",
      "Dataframe shape with only numeric value columns:  (51392, 6)\n",
      "Dataframe shape when nan value is dropped in label(Salary):  (12891, 6)\n",
      "The r-squared score for the model using only quantitative variables was 0.04113420903416998 on 3868 values.\n"
     ]
    }
   ],
   "source": [
    "# import 2017 dataset\n",
    "df_2017 = import_and_test('./survey_results_public_2017.csv', 'Salary', 'ExpectedSalary')\n",
    "label_to_predict = 'Salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "455b1089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017, get dummies method: from lectures code\n",
      "Shape of df:  (12891, 154)\n",
      "Object columns from this df:  141\n",
      "Shape of dummy df:  (12891, 21108)\n",
      "Shape of X:  (12891, 21107)\n",
      "The rsquared on the training data was 1.0.  The rsquared on the test data was -0.6116611493680051.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2017, get dummies method: my method\n",
      "Shape of df:  (12891, 154)\n",
      "Object columns from this df:  141\n",
      "Shape of dummy df:  (12891, 1366)\n",
      "Shape of X:  (12891, 1365)\n",
      "The rsquared on the training data was 0.8118050907109072.  The rsquared on the test data was -9.556389674176387e+25.\n"
     ]
    }
   ],
   "source": [
    "print('2017, get dummies method: from lectures code')\n",
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_2017, label_to_predict, create_dummy_lecture_method, dummy_na=False)\n",
    "print('-'*100)\n",
    "print('2017, get dummies method: my method')\n",
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_2017, label_to_predict, create_dummy_my_method, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe3f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1d8a873b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported dataframe shape:  (98855, 129)\n",
      "Dataframe shape with only numeric value columns:  (98855, 42)\n",
      "Dataframe shape when nan value is dropped in label(ConvertedSalary):  (47702, 42)\n",
      "The r-squared score for the model using only quantitative variables was 0.019991430883123606 on 14311 values.\n"
     ]
    }
   ],
   "source": [
    "# import 2018 dataset\n",
    "df_2018 = import_and_test('./survey_results_public_2018.csv', 'ConvertedSalary')\n",
    "label_to_predict = 'ConvertedSalary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ab753aa0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018, get dummies method: my method\n",
      "Shape of df:  (47702, 129)\n",
      "Object columns from this df:  87\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 467. MiB for an array with shape (10265, 47702) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [128]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# print('2018, get dummies method: from lectures code')\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_2018, label_to_predict, create_dummy_lecture_method, dummy_na=False)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print('-'*100)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2018, get dummies method: my method\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m test_score, train_score, lm_model, X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mclean_fit_linear_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_2018\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_dummy_my_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [116]\u001b[0m, in \u001b[0;36mclean_fit_linear_mod\u001b[1;34m(df, response_col, func_dummy, dummy_na, test_size, rand_state)\u001b[0m\n\u001b[0;32m     19\u001b[0m cat_cols \u001b[38;5;241m=\u001b[39m get_object_cols(df)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#Dummy categorical variables\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_dummy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of dummy df: \u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape)   \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#Split into explanatory and response variables\u001b[39;00m\n",
      "Input \u001b[1;32mIn [126]\u001b[0m, in \u001b[0;36mcreate_dummy_my_method\u001b[1;34m(df, cat_cols, _)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m categorize_feature(df1)\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df1], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\generic.py:4350\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4347\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   4349\u001b[0m bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m axis_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4350\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4353\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4356\u001b[0m \u001b[43m    \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4357\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4358\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_mgr)\n\u001b[0;32m   4359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\internals\\managers.py:685\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 685\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    693\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    694\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    701\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\internals\\managers.py:844\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    842\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    843\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 844\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    845\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1137\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m#  this assertion\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m new_mgr_locs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:163\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    158\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    160\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[1;32m--> 163\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    166\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:342\u001b[0m, in \u001b[0;36m_get_take_nd_function.<locals>.func\u001b[1;34m(arr, indexer, out, fill_value)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(arr, indexer, out, fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan):\n\u001b[0;32m    341\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[1;32m--> 342\u001b[0m     \u001b[43m_take_nd_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_info\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:518\u001b[0m, in \u001b[0;36m_take_nd_object\u001b[1;34m(arr, indexer, out, axis, fill_value, mask_info)\u001b[0m\n\u001b[0;32m    516\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(out\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape[axis] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 518\u001b[0m     \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_masking:\n\u001b[0;32m    520\u001b[0m     outindexer \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 467. MiB for an array with shape (10265, 47702) and data type uint8"
     ]
    }
   ],
   "source": [
    "print('2018, get dummies method: from lectures code')\n",
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_2018, label_to_predict, create_dummy_lecture_method, dummy_na=False)\n",
    "print('-'*100)\n",
    "print('2018, get dummies method: my method')\n",
    "test_score, train_score, lm_model, X_train, X_test, y_train, y_test = clean_fit_linear_mod(df_2018, label_to_predict, create_dummy_my_method, dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50ede3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec6844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcd42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66eb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b5abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "thk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
